{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Segmentacija srcanih komora.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN24oI9FjTuaa3nTh49AHYY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eNRRVX6nHDxr","colab_type":"text"},"source":["# Install and import dependencies"]},{"cell_type":"code","metadata":{"id":"UUIrUwXq4PhA","colab_type":"code","colab":{}},"source":["!pip install h5py\n","!pip install tensorflow-gpu\n","!pip install wandb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ZZ14PWS5nCr","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import time\n","import matplotlib.pyplot as plt\n","import h5py\n","import wandb\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Concatenate, Input, BatchNormalization\n","from tensorflow.keras.activations import relu, softmax\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.metrics import MeanIoU\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import load_model\n","from wandb.keras import WandbCallback\n","\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBlv-p6jHSuY","colab_type":"text"},"source":["# Fetching data from google drive"]},{"cell_type":"code","metadata":{"id":"DTBi9L9wMidD","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0mNHzcyRMi_Q","colab_type":"code","colab":{}},"source":["data = h5py.File('/content/drive/My Drive/Colab Notebooks/heart_chambers_data.h5', 'r')\n","print(list(data.keys()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zby-2w62Hkwk","colab_type":"code","colab":{}},"source":["x_train = data['x_train'].value\n","y_train = data['y_train'].value\n","x_val = data['x_val'].value\n","y_val = data['y_val'].value\n","x_test = data['x_test'].value\n","y_test = data['y_test'].value"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eCEq1B507-kb","colab_type":"text"},"source":["# Image data generator - augmentation"]},{"cell_type":"code","metadata":{"id":"-jRi9b2W8IND","colab_type":"code","colab":{}},"source":["train_datagen = ImageDataGenerator(\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","train_image_generator = train_datagen.flow(x_train, y_train, batch_size=32)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GHeCSw4O5dDl","colab_type":"text"},"source":["# Convolution blocks for UNet"]},{"cell_type":"code","metadata":{"id":"aoWxWTfo5cf1","colab_type":"code","colab":{}},"source":["def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n","\n","    p = MaxPool2D((2, 2), (2, 2))(c)\n","    return c, p\n","\n","\n","def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    us = UpSampling2D((2, 2))(x)\n","    concat = Concatenate()([us, skip])\n","\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n","\n","    return c\n","\n","\n","def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n","    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n","\n","    return c"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cb3MoI-353CA","colab_type":"text"},"source":["# UNet model function"]},{"cell_type":"code","metadata":{"id":"q7Wt1SxW509d","colab_type":"code","colab":{}},"source":["def create_UNet():\n","    f = [16, 32, 64, 128, 256, 512]\n","    inputs = Input((256, 256, 1))\n","    \n","    p0 = inputs\n","    c1, p1 = down_block(p0, f[0]) #256 -> 128\n","    c2, p2 = down_block(p1, f[1]) #128 -> 64\n","    c3, p3 = down_block(p2, f[2]) #64 -> 32\n","    c4, p4 = down_block(p3, f[3]) #32 -> 16\n","    c5, p5 = down_block(p4, f[4]) #16 -> 8\n","    \n","    bn = bottleneck(p5, f[5])\n","    \n","    u1 = up_block(bn, c5, f[4]) #8 -> 16\n","    u2 = up_block(u1, c4, f[3]) #16 -> 32\n","    u3 = up_block(u2, c3, f[2]) #32 -> 64\n","    u4 = up_block(u3, c2, f[1]) #64 -> 128\n","    u5 = up_block(u4, c1, f[0]) #128 -> 256\n","    \n","    outputs = Conv2D(4, (1, 1), padding=\"same\", activation=softmax)(u5)\n","    model = Model(inputs, outputs)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zfnNVDk6I1P2","colab_type":"text"},"source":["# Decoding one_hot_encoding function:"]},{"cell_type":"code","metadata":{"id":"Q3Mz2rYu-Bp7","colab_type":"code","colab":{}},"source":["threshold = 0.8\n","\n","def one_hot_decode(mask):\n","  decoded_mask = np.zeros((256,256))\n","  for i in range(4):\n","    for row in range(256):\n","      for col in range(256):\n","        if mask[row, col, i] > threshold:\n","          decoded_mask[row, col] = i * 85\n","\n","  return decoded_mask"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ASHL0RMvIU98","colab_type":"text"},"source":["# Train, evaluate, log and save model"]},{"cell_type":"code","metadata":{"id":"PwyeFgUj583X","colab_type":"code","colab":{}},"source":["epochs = 500\n","\n","run = wandb.init(project=\"Unet-heart-chamber\", entity=\"damirj\")\n","\n","model = create_UNet()\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[MeanIoU(4, name=\"mean_i_o_u\")])\n","model.fit(train_image_generator, epochs=epochs, validation_data=(x_val, y_val), callbacks=[WandbCallback()])\n","\n","test_evaluation = model.evaluate(x_test, y_test, batch_size=50, verbose=0)\n","wandb.log({\"Test accuracy\": test_evaluation[1]})\n","\n","predicted = model.predict(x_test)\n","stacked_images = []\n","for i in range(0, 80, 8):\n","  original_image = x_test[i].reshape((256,256)) * 255\n","  ground_truth_mask = one_hot_decode(y_test[i])\n","  prediction = one_hot_decode(predicted[i])\n","  prediction_eval = model.evaluate(x_test[i].reshape((1,256,256,1)), y_test[i].reshape((1,256,256,4)), verbose=0)\n","  stacked_img = np.hstack((original_image, ground_truth_mask, prediction))\n","  stacked_images.append(wandb.Image(stacked_img, caption=\"accuracy: {}\".format(prediction_eval[1])))\n","\n","wandb.log({\"Predictions (Original, Ground truth, Prediction)\": stacked_images})\n","\n","model.save(os.path.join(wandb.run.dir, \"model.h5\"))"],"execution_count":0,"outputs":[]}]}